# Features and Example Walkthrough

Let's start by understanding all of the learning experience activities available and how they might be used.

The `duckietown-lx` repository on GitHub contains the learning experiences developed by the Duckietown team - we'll 
walk through the [Object Detection](https://github.com/duckietown/duckietown-lx/tree/mooc2022/object-detection) LX here.

### Purpose

Every LX should revolve around a main goal or set of learning goals, documented at the beginning of the 
`README` file.  The description for the object detection LX reads:

This learning experience will take you through the process of collecting data from the Duckietown simulator and formatting it to be used to train a neural network to perform object detection using the robot's camera image. We will use one of the most popular object detection neural networks, called YOLO (v5). You will also have to integrate this trained model into the autonomy stack. For now we will just stop whenever an object (duckie) is detected in the road.

**TODO: Obj det walkthrough screenshots**

### Notebooks

### VNC Tool

### Simulation

### Duckiebot Agent

### Evaluation
